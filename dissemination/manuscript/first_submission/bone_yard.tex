
 In both conditions, the processing task was to judge the relevance of each word to a fictional ``moving'' scenario \citep{NairEtal16}.was an exact replication of the Implicit condition from Experiment 1. Because the Scenario Task requires participants consider the relevance of each word to a the same scenario, they are likely to maintain are representation of this scenario through the list presentation. In other words, participants are encouraged to activate the same mental attributes or dimensions for each item (e.g., ???), which will encourage mental context to remain in a similar part of the high-dimensional context space from item to item. As a result, mental context may remain relatively similar from item to item and reduce TCE. 












 Control processes have two relevant elements, the first is the fact that they are controlled, the second is that they change the nature of the processing. We can examine this by comparing the TCE in conditions where participants are motivated to engage controlled encoding processes (standard memory tasks) versus conditions where they have no impetus to engage controlled processing (i.e., implicit encoding conditions where they are assigned a processing task but do not know they will have to remember the items). One can then vary the type of processing task to examine the influence of type of processing. Such implicit instructions have seldom been used in free recall experiments. To my knowledge, the only exception is recent work by \citet{NairEtal16} who gave a susprize memory test as part of an experiment testing the survival processing account and found little TCE (though there was no explicit memory control condition). In Experiment 1 I test whether lack of intent to encode reduces TCE. In Experiment 2 I vary the type of proceesing participants engage in during an implicit task and show that contiguity depends not on the intent to encode per se, but on the type of processing.










% Can the TCE be observed under incidental encoding when controled processes are unlikely to be engaged? We do not know. The only study to measure the TCE implicit conditions \citep{NairEtal16} was the survival processing effect  and not the TCE per se. Although this study did not find a significant TCE, the lack of a control condition leaves it unclear whether the absence was due to intent. Therefore, Experiment 1 tests whether incidental encoding reduces TCE. 
% OR
% The only study to examine the TCE under implicit conditions \citep{NairEtal16} gave a surprise memory task after participants had rated a list of words on their relevance to scenarios and found no TCE. But because the focus of this study was the survival processing effect \citep{nair} and not the TCE per se, it did not include an explicit memory control condition leaving it unclear if the absence of intent or some other factor eliminated the TCE. Therefore, Experiment 1 tests whether incidental encoding reduces TCE. 


% Control processes have two relevant elements, the first is the fact that they are controlled, the second is that they change the nature of the processing. We can examine this by comparing the TCE in conditions where participants are motivated to engage controlled encoding processes (standard memory tasks) versus conditions where they have no impetus to engage controlled processing (i.e., implicit encoding conditions where they are assigned a processing task but do not know they will have to remember the items). One can then vary the type of processing task to examine the influence of type of processing. Such implicit instructions have seldom been used in free recall experiments. To my knowledge, the only exception is recent work by \citet{NairEtal16} who gave a susprize memory test as part of an experiment testing the survival processing account and found little TCE (though there was no explicit memory control condition). In Experiment 1 I test whether lack of intent to encode reduces TCE. In Experiment 2 I vary the type of proceesing participants engage in during an implicit task and show that contiguity depends not on the intent to encode per se, but on the type of processing.

% % These positions can be distinguished by removing encoding control processes from the equation using an implicit paradigm in which participants are given a surprise memory task after having made a judgment about a list of words. Unfortunately, 


% % Forming a better understanding of how processing influences contiguity is critical, as some theories suggest that contiguity is fundamental principle of memory that is independent of control processes \citep{HealEtal14,LohnEtal14} whereas others suggest that contiguity is purely a biproduct of strategic processing \citep{Hint16}. 

% % Indeed, some models of contiguity could be taken to suggest that optional encoding processes are a thin veneer on obligatory processes that would operate even in implicit conditions where participants are not even trying to encode new information \citep{Hint}. 

% % \citep[see][for evidence that this might be the case]{NairEtal16}.




% % In the first experiment, 

% % hich types of processing do and do not give rise to contiguity



% % contiguity effect has been important. 
% % But, this work on contiguity has not extensivly considered control processes. As such there is little understanding of how variation in processing impacts ontiugity \citep{Hint}. 

% % A first step is to simply eliminate memory control processes from encoding by doing an implicit task. 

% % We first replicate that effect, then consider which specific processes are responsible. 





###########
% But it is not clear if the TCE depends on the intent to encode per se, or rather on processes that just happen to be discouraged by the type of processing.

% These results show that the contiguity effect can disappear when participants do not intend to encode the items and are instead given a surprise free recall test \citep[see also,][]{NairEtal16}. But it is not clear why the effect disappears. Clearly, it has something to do with differences in how people process the words when they are deliberately trying to remember them. But are these critical contiguity-generating processes encoding strategies that depend on the intent to encode per se \citep{Hint16}, or are they more general processes that 



% #############
% % those features and 2) consider a variety of other processing tasks that share some, but not all, of these features. The goal is not to precisley the quantify the differences between contigutiy tasks or a particualy hypothesis about wich features of the task are critiucal. Instead it is a bmore basic wuations whether the absence of intent to encode contiguity necessiarly abolishes contiguity, or whether it depends on the nature of the processing task. 


% % To the extent that memories are of particular episodes, and an episode is composed of the whole meliue of brain activity at a particular moment, then the psychological distance between memories should be a direct function of how much the pattern of activity has changed from moment to moment. 




% % The processing required by the Size Task has two features that are likely candidates for modulating contiguity. First, participants must consider the same attribute of each item---its size. If we think of attributes as roughly corresponding to dimensions in mental context space \citep{ATTRIBUTE THEORY}, then the task forces participants to activate the same dimension for each item and may discourage activation of other dimensions for example when evaluating if a baseball can fit in a shoe box, participants may not activate non-relevant attributes such as its semantic associates (stadium, fans, champions). Therefore items may activate a more impoverished mental context than if they were processed under a different task. Second, 

% % So in this experiment we 1) attempt to replicate the lack of contigutiy under implicity encoding using a different task that shares those features and 2) consider a variety of other processing tasks that share some, but not all, of these features. The goal is not to precisley the quantify the differences between contigutiy tasks or a particualy hypothesis about wich features of the task are critiucal. Instead it is a bmore basic wuations whether the absence of intent to encode contiguity necessiarly abolishes contiguity, or whether it depends on the nature of the processing task. 





#############
context drift and processing




Both of these theories suggest that intent to encode changes the way participants process the stimuli. The encoding strategy account suggests they deliberately attempt to encode a chain of items. The context account suggests that intent to encode promotes processing that causes context to drift more rapidly. In either case it should be possible to produce a contiguity effect in the absence of intent to encode by encouraging participants to process the items in a way that mimics how they process them while attempting to learn they. 



If you think of mental context as a high dimensional space in which dimensions correspond to psychologically salient aspects of stimuli, like color, shape, semantics, then asking people to evaluate items on the same dimension would reduce context drift. By contrast, if you asked participants to evaluate each item on a different dimension, it would encourage more drift.


Implicit encoding instructions were used in all conditions because it should reduce the tendency for participants to engage in additional processing of the words beyond that needed to complete the assigned processing task and because it will allow us to determine if different types of processing can produce contiguity in the absence of intent to encode.




And the contrst between the condition in which you are asked to form a detailed, multi-facted image of each item versus the condition in which you are required to form an image along a singal dimension which is consistent from item to item, captures the notion that it is the drift of context that is critical.


When participants expect their memory will be tested they likely engage in many processes beyond those strictly required to make a judgment about the items. But if people do not expect their memory will be tested it is much more likely that they will do the processing required to complete the task and nothing more.


First, subjects must be forming associations between item representation and the context representation. Second, the state of the context representation must be drift in such a way that the similarity between the state at two points in time is a decreasing function of the amount of time separating those events. That is, there will be little to no contiguity if context is either stable or drifting very slowly. 





Under this hypothesis the difference between the explicit and the implicit encodiund condition is not intent to encode per se, but that trying to remember the items encourages additional processing beyond that required to complete the Scenario Task, such as considering aspects of the item that are not relevant to the task such as its color, shape, smell, etc. This additional processing could cause context to drift more rapidly in the intentional than the incidental condition creating a difference in contiguity. 


Under context, the only critical feature of intent to encode is that it drives context drift. 



A different processing task that involves a less vivid mental representation might generate more contiguity. For example, judging the size of an item, a common encoding task, requires...  




By contrast, Any form of processing that causes the pattern of brain activity to change rapidly from item to item should generate a graident of simuilarity across lags and therefore generate a contiguity effect.




And the contrst between the condition in which you are asked to form a detailed, multi-facted image of each item versus the condition in which you are required to form an image along a singal dimension which is consistent from item to item, captures the notion that it is the drift of context that is critical.