\documentclass[jou,natbib,floatsintext]{apa6} %apa 6th edition format

% watermark for first page
% \usepackage[firstpage]{draftwatermark}
% \SetWatermarkText{In Prep}
% \SetWatermarkScale{.75}
% \SetWatermarkColor[gray]{0.88}

\usepackage{amstext,amssymb,graphicx,bm,soul,color,url,lscape,rotating,setspace,csquotes,pdflscape,rotating}
% \DeclareDelayedFloatFlavor{sidewaystable}{table}
% \DeclareDelayedFloatFlavor{sidewaysfigure}{figure}


\usepackage[space]{grffile}

% as setup by apacite, natbib puts extra spaces between the commas and semicolons in the cites. This fixes it:
\setcitestyle{citesep={;},aysep={,}}
 
% Run texcount on tex-file and write results to a file
\newcommand\wordcount{\input{wordcount.sum}}

% environment to display a page in landscape in the final pdf
\newenvironment{rotatepage}%
    {\pagebreak[4]\global\pdfpageattr\expandafter{\the\pdfpageattr/Rotate 180}}%
    {\pagebreak[4]\global\pdfpageattr\expandafter{\the\pdfpageattr/Rotate 0}}%

% commands for inserting values determined by analyses scripts.
\input{figures/table_values}

% counter for panels of crp matrix figure
\newcounter{crppanel}

% commands for making margin notes marked with authors initials
\setlength{\marginparwidth}{30pt}
\newcommand{\mkh}[1]{\marginpar{\scriptsize \textcolor{red}{MKH: #1}}}

\title{Temporal Contiguity in Incidentally Encoded Memories} 

\author{M.\ Karl Healey}

\affiliation{Michigan State University}

\shorttitle{Contiguity with Incidental Encoding}

%\journal{???}

\authornote{I thank Mitchell Uitvlugt and Kimberly Fenn for helpful discussions. Correspondence concerning this article should be addressed to M. Karl Healey (khealey@msu.edu) at Michigan State University, Department of Psychology, 316 Physics Road, East Lansing, MI.
\begin{flushleft}
phone: 517-432-3107\\
Version of \today\\
\wordcount Words (Approximate due to use of \LaTeX)
\end{flushleft}
}

\abstract{Similarity is a key principle of memory: recalling one event triggers recall of similar events. The amount of time separating two events is believed to be a powerful determinant of similarity. If so, there should be a strong Temporal Contiguity Effect whereby thinking of one event triggers recall of other events experienced nearby in time. This effect has been observed, but its source remains a matter of debate. Is it due to task-general automatic processes that operate whenever new memories are formed? Or is it due to task-specific encoding strategies that operate only during intentional rote learning? I test these theories by looking for the Temporal Contiguity Effect when there is no intent to memorize, as is often the case outside the laboratory. Experiment's 1 and 2 confirm that temporal contiguity can absent under incidental encoding. Experiment 3 shows that it is not the intent to memorize per se, but rather how subjects process information while incidentally learning it that generates temporal contiguity.}

\keywords{episodic memory; free recall; temporal contiguity}

\begin{document}
\maketitle

Recalling one event tends to trigger recall of other events experienced nearby in time \citep{HealKaha17}. This Temporal Contiguity Effect (TCE) manifests in many tasks \citep{DaviEtal08,SchwEtal05}. For example, in free recall, you study words presented serially and recall them in any order. After recalling the word studied in the $5^{th}$ serial position, your next recall is much more likely to be from the $6^{th}$ or $4^{th}$ position than more distant positions \citep{Kaha96}. 

The TCE has shaped theories of the testing effect \citep{KarpEtal14}, directed forgetting \citep{SahaEtal13}, retrieval induced forgetting \citep{KlieBaum16}, childhood development \citep{JarroEtal15}, cognitive aging \citep{WahlHuff15,HealKaha15}, event segmentation \citep{EzzyDava14}, time estimation \citep{SahaSmit13}, and even perception \citep{TurkEtal12}. Yet, we still do not know which cognitive processes create the effect \citep{HealKaha17}. Here we will consider two classes of explanation. First, that the TCE arises from control processes that are only engaged when we are deliberately forming new memories. Second, that the TCE arises from processes the memory system automatically engages whenever new memories are formed be it deliberately or incidentally.   

Control processes \citep{LehmMalm13,RaaiShif81} allow us to strategically process information during memory encoding, maximizing recall \citep[e.g.,][]{Unsw16}. Some work suggests that the TCE arises from such task-specific strategies, implemented by control processes to handle the idiosyncratic demands of laboratory tasks \citep{Hint16}. For example, in a standard free recall task, subjects may adopt the strategy of linking successive list items together to tell a story. Alternatively, a strategy like the method of loci could be adopted. The key feature is that subjects deploy these strategies only because they happen to be well-suited to the specifics of the task, not because the strategies make use of task-general mechanisms that are fundamental to human memory. Thus, such an account predicts the TCE should disappear under incidental encoding \citep{Hint16}.

Other theories suggest that the TCE is produced by task-general processes that operate even when we form new memories in the absence of deliberate study. For example, some models assume that, as list items are presented they form associations to a representation of time \citep{HowaEtal14a,BrowEtal07} or drifting mental context \citep{LohnEtal14}. Alternatively, contiguity might arise form temporally adjacent items spending time together in working memory and thus becoming linked. The key feature is that these contiguity-generating processes are assumed to underlie memory across a range of situation including those that do not involve deliberate study. Thus, such an account  predicts that the TCE should be observed even under incidental encoding.

Of course, these two accounts are not mutually exclusive. \citet{Hint16}, for example, suggests that people engage in deliberate strategies but might also automatically notice similarities among temporally proximate items and therefore remember them together at recall. But so little work has been done in this area that we do not know the answer to even basic questions. We focus on perhaps the most basic: are control processes necessary to generate the contiguity effect or are automatic processes sufficient? On this question, the two perspectives make competing predictions about the influence of removing the intention to encode ---that it should or should not eliminate the TCE. These predictions have never been directly tested. The only study to measure the TCE after incidental encoding \citep{NairEtal17} did not include an explicit encoding control condition because the TCE was not its main focus. Tantalizingly, this study did \emph{not} find a significant TCE (a finding they replicated in XX experiments). But the lack of a control condition leaves the reason unclear. Therefore, Experiment 1 directly compares the TCE under explicit and incidental encoding.




\section{Experiment 1}
As an initial experiment, we attempted to conceptually replicate the \citet{NairEtal17} finding of no TCE under incidental encoding. To facilitate comparison with other studies in the TCE literature, we included an explicit encoding control condition and used standard free recall methods and a commonly used encoding task. 

All subjects viewed a list of words presented on at a time and made a simple judgment about each. After the last item, all subjects were asked to recall as many of the words as they could, in any order. Participants in the Explicit condition were expecting this memory test; participants in the Incidental condition were \emph{not} expecting any memory test. 

\section{Method}

% setup some commands to make changing text from study to study easy
\newcommand\listlength{16} % words per list 
\newcommand\presrate{4 seconds} % time per word
\newcommand\isi{1 second} %
\newcommand\DFRDelay{16 second} % length of distractor at end of study
\newcommand\recalltime{75 seconds} % time to recall
\newcommand\totalss{XX}
\newcommand\totalexcluded{XX}



\subsection{Data Sharing}All data analyzed in this report are freely available on the author's website (https://cbcc.psy.msu.edu/data/Heal16implicit.csv).

\subsection{Subjects}

Given that manipulating encoding intention might reduce, but not eliminate, the TCE, it is critical to have sufficient power to detect small effects. \citet{SedeEtal10} reported a meta-analysis of the TCE in explicit encoding studies; power calculations reveal that a sample size of 143 per condition would provide a $1-\beta$ power of 0.95 to detect (via a 1-tailed 1-sample t-test) an effect one fifth the size of the average effect they reported. 
% here is how to get the SD: ((.614-.5)/31.2)*np.sqrt(510)
In order to collect enough data to meet or exceed this sample size in the Incidental conditions, subjects for all of the experiments reported here were recruited using Amazon's Mechanical Turk, a crowdsourcing website that allows for efficient collection of large volumes of high-quality data. Subjects were paid \$1.00 for participating (a rate of roughly \$10 / hr).

Subjects in the Incidental conditions were excluded from analysis if they reported in a post-experiment questionnaire that they suspected their memory would be tested while they were preforming the incidental encoding task. The final analyzed sample was composed of \shoeExplicitIncluded~in the Explicit condition and \shoeIncidentalIncluded~in the Incidental condition. Table~\ref{sampsize_table} shows the total number of included and excluded subjects for each experiment.

\subsection{Procedure}
All subjects completed two free recall lists (only the first of which is analyzed here). Each list was composed of \listlength~words drawn randomly from a pool of 1638 words, with the constraint that no word was used more than once for a given subject. Words were presented one at a time on the subject's computer screen for \presrate. This presentation rate was deliberately chosen to be slightly faster than the 5 seconds per word used by \citet{NairEtal17} to reduce the amount of ``free time'' subjects have between making the judgment and the presentation of the next word.
There was an inter-stimulus interval of \isi~between word presentations during which a fixation cross was displayed in the same location in which the words appeared. The final word of each list was followed by a \DFRDelay~distractor period during which subjects answered math problems of the form $A+B+C=$?, where $A$, $B$, and $C$ were positive, single-digit integers, though the answer could have been one or two digits. Subjects typed their answers to the math problems in a text-box and pressed enter to submit. Upon pressing enter, a new math problem and a new blank text-box appeared. Subjects were instructed to ``Try to solve as many problems as you can without sacrificing accuracy. The task will automatically advance when the time is up.''.

Following the math distractor task, subjects in both conditions were asked to recall as many items as possible from the preceding list, in any order. Subjects typed each recalled word in a text-box and pressed enter to submit the word. Upon pressing enter, the word disappeared and a new blank text-box appeared such that subjects could not see their prior responses. Subjects were given \recalltime~to recall as many words as they could. To ensure subjects noticed that the recall period had begun (e.g., were not looking at the keyboard and typing their answer from the final math problem), a red screen was flashed for 500 ms before the recall instructions were displayed and the recall text-box did not begin accepting input for a further 500 ms. Therefore, including the math distractor, there was a total delay of $16+0.5+0.5=17$ seconds between the end of the study period and the beginning of the recall period. A spell-checking algorithm (described in the supplemental materials) checked subjects typed responses for typos and scored their recall accuracy.

% sample size table
\begin{table}
\caption{Sample sizes, exclusions, and recall probability by condition.}
\label{sampsize_table}
\begin{tabular}{llcccc}
\thickline
    Exp & Condition & $n$ Included & $n$ Excluded  & Recall  \\
     &  &  &  (aware) & Prob. (SD) \\
  Exp1  \\
  & Explicit &  \shoeExplicitIncluded & \shoeExplicitAware & \shoeExplicitPrec \\
  & Incidental &  \shoeIncidentalIncluded & \shoeIncidentalAware & \shoeIncidentalPrec \\
    Exp2  \\
  & Explicit &  \doorExplicitIncluded & \doorExplicitAware & \doorExplicitPrec \\
  & Incidental &  \doorIncidentalIncluded & \doorIncidentalAware & \doorIncidentalPrec \\
  Exp3  \\
  & Weight &  \WeightIncluded & \WeightAware & \WeightPrec \\
  & Animacy &  \AnimacyIncluded & \AnimacyAware & \AnimacyPrec \\
  & Scenario &  \ScenarioIncluded & \ScenarioAware & \ScenarioPrec \\
  & Movie  &  \MovieIncluded & \MovieAware & \MoviePrec \\
  & Relational &  \RelationalIncluded & \RelationalAware & \RelationalPrec \\
  
\hline
\end{tabular}
\end{table}

\subsubsection{Encoding Instructions Manipulation} Subjects were randomly assigned to either the Incidental condition or the Explicit condition. Prior to seeing the first list, subjects in both conditions were told that they would see a series of words and would make a simple judgment about each one (i.e., Would it fit in a shoebox?). The exact instructions depended on the condition. In the Explicit condition, subjects were given standard free recall instructions that described the size judgment task but emphasized memory. In the Incidental condition, subjects were given instructions only for the size judgment task and memory was never mentioned. Because the wording of the instructions are integral to the intent manipulation, they are reproduced exactly in the Supplementary Materials.

\subsubsection{Shoebox Task} In both conditions subjects were asked to make a size judgment about each word while it was present on the screen. Specifically, they were asked  to judge if the word referred to an object that would fit into a shoebox. To allow for the same yes/no response for each task, subjects were asked to indicate if the judgment was easy to make under the guise of norming the items for a later study. See the supplemental materials for the exact task instructions as well as measures taken to ensure subjects understood the task instructions.

\subsection{Quantifying the Temporal Contiguity Effect} The TCE is most often examined using a \textit{lag conditional-response probability} function or lag-CRP. The lag-CRP gives the probability that recall of an item studied in position $i$ of a study list will be followed by recall of an item studied in position $i+lag$. For example, if recall of the item from position 5 was followed by recall of the item from position 6 the lag would be 1. If, however, it was followed by recall of the item from position 3, the lag would be -2. For each lag, the CRP is computed by dividing the number of times a transition of that lag was \emph{actually} made by the number of times it \emph{could} have been made \citep[e.g., it could not have been made if the item $i+lag$ was already recalled;][]{Kaha96}. The lag-CRP is typically highest for lags 1 and -1 and decreases sharply for larger absolute values of lag. If the TCE is reduced under incidental encoding conditions, the lag-CRP should be flatter.

The lag-CRP provides a visual representation of the TCE, but it is useful to have a single number that quantifies the size of the effect. For this purpose, the \emph{temporal factor score} is typically used \citep{SedeEtal10,PolyEtal09}. The temporal factor score is computed by ranking the absolute value of the lag of each actual transition with respect to the absolute values of the lags of all transitions that were possible at that time, which provides a percentile score for each transition. Averaging these percentile scores across all of a subject's transitions provides the temporal factor score.
 
When evaluating the size of the TCE, it is important to take into account the fact that the likelihood of successful recall is not random with respect to serial position (e.g., primacy and recency effects, or more generally autocorrelations in goodness of encoding), which can artificially increase the size of the TCE \citep{HealKaha17,Hint16}. The size of this artificial TCE can be measured by taking the items which a subject actually recalled for a given list, randomly shuffling (i.e., permuting) the order of recalls, and recomputing the temporal factor score. Repeating this permutation procedure many times provides a distribution of the temporal factor score expected if recall transitions are completely random with respect to lag \citep{HealKaha17}. This logic was used to provide a corrected measure of the TCE for each participant. For each list, the temporal factor score was computed for the actual recall sequence and for 10,000 random permutations of the sequence. The actual temporal factor score was then converted into a z-score, Z(TCE), by subtracting the permutation distribution's mean and dividing by its standard deviation. In the absence of a true TCE, the expected value of Z(TCE) is zero, so we can test for a TCE by determining if the across-subject average of Z(TCE) is significantly above zero.   


\section{Results and Discussion}

Figure~\ref{shoebox} shows the lag-CRP and corrected temporal factor scores for the Explicit and Incidental conditions. The Explicit condition shows a clear TCE: the lag-CRP is highest for short lags (i.e., $|lag|=1$) and decreases for larger lags. Moreover, the 95\% confidence interval on the Z(TCE) lies well above zero. By contrast, the Incidental condition shows no evidence of a TCE: the lag-CRP is nearly flat and the 95\% confidence interval on the Z(TCE) includes zero. Overall recall probability (Table~\ref{sampsize_table}) was also lower in the Incidental condition.


\newcommand\paneltext{(A) Lag-conditional response probability functions. Error bars are bootstrapped within-subject 95\% confidence intervals. (B) The average Z(TCE).  Error bars are bootstrapped between-subject 95\% confidence intervals. Z(TCE) for a given subject is computed as follows: An observed temporal factor score was computed as the average percentile ranking the temporal lag of each actual transition in the recall sequence with respect to the lags of all transitions that were possible at that time. To determine the temporal factor score expected by chance, a permutation distribution was created by randomly shuffling the order of recalls within the sequence 10,000 times and computing a temporal factor score for each shuffling. The reported value, Z(TCE), is z-score of the observed temporal factor score within the permutation distribution.}
\begin{figure*}
\fitfigure{figures/shoebox.pdf}
\caption{The temporal contiguity effect (TCE) with the Shoebox size judgment task under explicit versus incidental encoding. \paneltext}
\label{shoebox}
\end{figure*}

These results suggest that removing the intent to encode eliminates the TCE.

Because the TCE has proven to be so robust in previous studies \citep{HealKaha17}, we attempt to replicate the finding in Experiment 2 using a slightly different processing task.

\section{Experiment 2}
\section{Method}

The methods were identical to those used in Experiment 1 except for the judgment task instructions (see Table 1 for sample size information).

The processing required by the Shoebox Task from Experiment 1 is quite simple. So simple that one could argue it is  ineffective at forming strong memories, which may artificially reduce the TCE. Therefore, we wanted to retain the basic task of judging size while increasing memory performance in the Incidental condition. That is, can processing that promotes memory do so without producing substantial contiguity? Mental imagery and self-referential processing are two effective ways to improve memory. Thus, the Front Door Judgment task asked subjects to imagine trying to move the object referred to by each item through the front door of their house and decide whether or not it would be possible (again, subjects were asked to indicate if this judgment was easy or difficult to make by pressing ``Y'' or ``N'').
%This Front Door task, should encourage subjects to form a more vivid and self-relevant mental image than the Shoebox task.
See the supplemental materials for the exact task instructions.

\section{Results and Discussion}
As predicted, the Front Door Task substantially improved memory accuracy in the Incidental condition. In fact, probability of recall was equal in the Explicit and Incidental conditions (Table 1). Nonetheless, the Front Door task did not produce a significant TCE under incidental encoding: Figure~\ref{door} shows that whereas the Explicit condition showed a distinctly peaked lag-CRP and a Z(TCE) significantly above zero, the Incidental condition showed a flattened lag-CRP and a Z(TCE) for which the confidence interval included zero. These results confirm that incidental encoding can eliminate temporal contiguity without substantially decreasing memory performance. This lack of coupling between level of recall and level of temporal contiguity has important theoretical implications, which we will consider in the discussion.


\begin{figure*}%[hp]
\fitfigure{figures/FrontDoor.pdf}
\caption{The temporal contiguity effect (TCE) with the Front Door size judgment task under explicit versus incidental encoding. \paneltext}
\label{door}
\end{figure*}








\section{Interim Discussion}
Experiments 1 and 2 show that the TCE can be absent when intent to encode is absent. This result is consistent with theories that ascribe the TCE to strategic control processes. Under this interpretation, the contiguity-generating processes are more or less inseparable from the intent to encode. But is intent to encode truly necessary to find a TCE? Perhaps not.

An alternate interpretation is that automatic encoding processes do produce contiguity but their effect is obscured by processes required by the judgment task. For example, most models produce a TCE because the representations of items studied close together are more similar to each other than they are to representations of items studied far apart. The Shoebox and Front Door tasks encourage subjects to maintain a common mental representation (e.g., image of a shoebox) throughout the list presentation. If this representation is incorporated into the representations of list items, it would increase the similarity of items separated by distant lags, attenuating the TCE. When effortfully memorizing, subjects likely process items in ways that are not necessary of the judgment task, perhaps decreasing the similarity of items separated by distant lags, increasing the TCE. That is, the judgment task might decrease the TCE in a way that is not due to the lack of intent to encode.

More generally, if intentional control processes are required to produce contiguity, it should be challenging, perhaps impossible, to observe a TCE under incidental encoding. But if control processes simply moderate the effect of automatic contiguity-generating processes (sometimes attenuating the TCE, sometimes accentuating it), it should be easy to find incidental encoding tasks that produce a TCE. Experiment 3 tests these predictions by examining five different encoding tasks.

\section{Experiment 3}
\section{Method}
The question is no longer whether Explicit encoding produces a larger TCE than Incidental encoding, but rather whether the TCE can ever be observed under Incidental encoding. Thus, in Experiment 3 all subjects were given Incidental encoding instructions, but were randomly assigned to one of five different judgment tasks that varied in the type of processing required. Otherwise, the methods were identical to those used in Experiments 1 and 2 (see Table 1 for sample size information).

\subsection{Processing Task Manipulation}
In all conditions, subjects were asked to make a judgment about each word as it was presented. Here, we describe the type of processing that each task was intended to discourage (or encourage). Again, to allow for the same yes/no response for each task, subjects were asked to indicate if the judgment was easy to make under the guise of norming the items for a later study. See the supplemental materials for the exact task instructions.

\subsubsection{Weight Task} The Weight Task was similar to the size judgment tasks used in the first two experiments except that it asked subjects to compare each item's \emph{weight} to a common referent: a bottle of water. Specifically, they were asked to judge whether each word referred to an object that was heavier than ``a standard bottle of water you'd purchase from a vending machine''. Because weight is not an easily visualizable attribute, the Weight Task might be expected to reduce the likelihood that subjects will maintain the same vivid mental image throughout the list. Thus, it may produce a larger TCE if associating each item with a common mental image tends to attenuate the TCE.

\subsubsection{Animacy Task} The Animacy Task asks subjects whether each item refers to an object that is living or non-living. Like the Shoebox, Front Door, and Weight tasks, the Animacy task requires subjects to consider only a single attribute of each item (i.e., animacy status). But unlike the aforementioned tasks, it does not provide a reference object against which to compare each item. Thus, it further reduces the likelihood of maintaining a single vivid image throughout the list. 

\subsubsection{Scenario Task} The Scenario Task asks subjects to judge the relevance of each word to a scenario: moving to a foreign land \citep{NairEtal17}. Subjects are likely to maintain some representation of this scenario across items, but because it does not specify any pre-existing dimension, like size or weight, each item may be expected to activate many different attributes, lowering the similarity of mental representations from item to item.

\subsubsection{Movie Task} The instructions for the Movie Task explain that ``when you read a word, it can trigger many different thoughts'' and gives the example of the word baseball triggering a series of thoughts: ``you might have a mental image of a baseball, you might hear the crack of a bat hitting a ball, you might think of related concepts like ballpark, players, and fans...''. It then asks subjects to allow each item ``to activate as many different thoughts as possible. Then use these thoughts to generate a mental movie (like a detailed image of spending an afternoon at a baseball game or what it is like to be a player on a baseball field).'' Subjects then judge whether or not it was easy to form such a mental movie. This tasks removes the requirement to consider each item along the same dimensions and instead encourages subjects to think deeply about the unique attributes of each item, which might be expected to cause very different mental representations to be activated with each successive item, perhaps increasing the TCE. 

\subsubsection{Relational Task} The Relational task is similar to the Movie Task except instead of being asked to make a new mental movie for each item, subjects are asked to ``try to incorporate each new word into your existing mental movie. For example, if the next word was "owner", you should allow it to activate many associated thoughts and then incorporate it into your existing ``ballpark'' movie.'' This condition encourages subjects to notice semantic associations between temporally proximate items, much like the ``reminding'' process \cite{Hint16} suggested contributes to the TCE. Thus, this condition should maximize the chance of observing a TCE. 

\section{Results and Discussion}

As seen in Figure~\ref{E3}, all of the processing tasks produced a TCE under incidental encoding conditions. For each task, the lag-CRP tends to decrease with increasing $|lag|$ and the Z(TCE) is significantly above zero. These results show that while the TCE can be attenuated under incidental conditions (as in Experiments 1 and 2), the lack of intent to encode, per se, does not eliminate contiguity. 

Indeed, perhaps the most remarkable feature of the data is how little the size of the TCE differs among the tasks, consistent with the suggestion that the TCE is due to automatic encoding processes. The only condition for which the z(TCE) differed significantly from any other condition was the Relational Task condition, which asked subjects to integrate each item in to an ongoing movie. This suggests that encouraging subjects to notice semantic similarities among items does indeed enhance temporal contiguity \citep{Hint16}, at least  under incidental encoding conditions. 

It is also notable that variation in the level of contiguity across conditions is unrelated to variation in the level of recall (see Table 1). Figure 4 plots level of recall versus level of TCE across all conditions from Experiments 1, 2, and 3. Although the correlation is positive, it is small and not significant.  This finding replicates the \citep{NairEtal17}, who found variation in recall without variation in contiguity, and suggests that the coupling between level of temporal contiguity and recall success is not as strong as has been suggested by analyses of individual differences in free recall of explicitly encoded lists \citep{SedeEtal10,Healetal14}. 

Finally, we note that although Experiments 1 and 2 conceptually replicated Nairne et al.'s (2017) finding of no contiguity under incidental encoding using different encoding tasks, Experiment 3 failed to replicate the finding using an encoding task (Survival Scenario) almost identical to Nairne et al.'s. This failure may be due to our larger sample size ($n=299$ here versus $N=80$ in E1 and $N=80$ in E2 of Nairne et al.) providing more power to detect a small contiguity effect combined with seemingly minor methodological differences (e.g., different list lengths and presentation rates). In any case, the message across the present three experiments is consistent with Nairne et al.'s findings: incidental encoding \emph{can} eliminate contiguity and it certainly reduces the size of the effect relative to explicit encoding. 

\begin{figure*}%[hp]
\fitfigure{figures/E3.pdf}
\caption{The temporal contiguity effect (TCE) under incidental encoding with different judgment tasks. (Top Row) Lag-conditional response probability functions. Error bars are bootstrapped within-subject 95\% confidence intervals. (Bottom Row) The average Z(TCE).  Error bars are bootstrapped between-subject 95\% confidence intervals. Z(TCE) for a given subject is computed as follows: An observed temporal factor score was computed as the average percentile ranking the temporal lag of each actual transition in the recall sequence with respect to the lags of all transitions that were possible at that time. To determine the temporal factor score expected by chance, a permutation distribution was created by randomly shuffling the order of recalls within the sequence 10,000 times and computing a temporal factor score for each shuffling. The reported value, Z(TCE), is z-score of the observed temporal factor score within the permutation distribution.}
\label{E3}
\end{figure*}









\section{General Discussion}
Does the TCE depend on control processes that implement task-specific strategies during deliberate encoding \citep{Hint16}? Or are automatic processes that operate even when we form new memories in the absence of deliberate study sufficient to produce a TCE \citep{HealKaha17}? The former possibility suggests the TCE should be easily eliminated by removing the impetus to engage controlled processes. The latter suggests the the TCE should be observable under most encoding circumstances. The data tell us that neither view is totally correct.

Experiment 3 showed that the TCE is not completely dependent on intent to encode: a robust TCE was observed in five different implicit tasks. These results are an existence proof for temporal contiguity under incidental encoding and rule out the possibility that the TCE is an artifact task-specific strategies implemented by controlled encoding processes. The TCE seems to arise from automatic encoding processes. The bigger contribution of these data, however, is to point out serious limitations of existing models of these automatic encoding processes. 


\begin{figure}%[hp]
\fitfigure{figures/corr.pdf}
\caption{The size of the temporal contiguity effect versus the overall level of recall. Each dot represents the average of one of the conditions 9 conditions reported across the 3 experiments.}
\label{door}
\end{figure}

Experiments 1 and 2 showed that intent to encode matters a great deal: in these experiments, the TCE was eliminated when controlled encoding processing was discouraged via incidental encoding instructions and particular types of processing were encouraged by the judgment task. This finding points to a gap in our understanding of how encoding processes influence contiguity. There have been few attempts to model how automatic memory processes interact with controlled processes to meet task demands \citep{LehmMalm13,PolyEtal09}, thus existing models would likely have difficulty accounting for the difference between Explicit and Incidental conditions. The challenge is avoiding adding a homunculus to the models that does the hard work of translating task instructions into changes in encoding processes. What computational mechanisms allow instructions to regulate encoding processes?

Equally important is the finding that variations in the size of the TCE is not tightly coupled with variations in overall recall levels (Figure 4). This is most dramatically illustrated in Experiments 1 and 2 where there was no significant TCE but substantial recall. Indeed, some of the conditions with the highest recall levels had the lowest levels of contiguity. This finding may pose a challenge for models that assume episodic memory for an event is fundamentally mediated by its associations to a temporal representation \citep[e.g.,][]{LohnEtal14,HealKaha15}. All else being equal, such models predict that the contiguity effect would be strongly attenuated by any manipulation that also attenuates formation of new episodic memories, such as incidental encoding instructions. Unless those models include other sources of associations, such as semantic associations \citep{PolyEtal09}, that can support memory in the absence of temporal contiguity, they may have difficulty accounting for the data of Experiments 1 and 2. Determining whether existing models can adequately fit these data will be an important target for future work.

In summary, these results show that control processes are not necessary to produce a TCE, but that they can powerfully influence the size of the effect, and even eliminate it. Thus, the results point to serious limitations in existing theories of TCE---we understand much about how memory encoding processes produce temporal contiguity, but we understand little about how these processes are controlled.

\bibliography{healey_lab}
\end{document}